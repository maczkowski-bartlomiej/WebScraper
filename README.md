ğŸŒ Webscraper - Skaner Stron Internetowych ğŸš€

Projekt przygotowany na uczelnie

ğŸ“‹ Opis projektu

Webscraper to narzÄ™dzie umoÅ¼liwiajÄ…ce uÅ¼ytkownikom skanowanie stron internetowych w celu pozyskania kluczowych danych, takich jak tytuÅ‚y stron, adresy e-mail, liczba linkÃ³w wewnÄ™trznych, struktura organizacyjna czy statystyki tagÃ³w HTML. Aplikacja skÅ‚ada siÄ™ z trzech gÅ‚Ã³wnych moduÅ‚Ã³w: interfejsu uÅ¼ytkownika, silnika skanowania oraz bazy danych, ktÃ³re wspÃ³Å‚dziaÅ‚ajÄ… w harmonijny sposÃ³b. ğŸ› ï¸

âœ¨ GÅ‚Ã³wne funkcjonalnoÅ›ci





Wprowadzanie adresÃ³w URL ğŸ“: UÅ¼ytkownik moÅ¼e wprowadziÄ‡ listÄ™ adresÃ³w URL (oddzielonych przecinkami) za pomocÄ… intuicyjnego interfejsu.



Asynchroniczne skanowanie âš¡: Szybkie i wydajne przetwarzanie wielu stron dziÄ™ki asynchronicznym Å¼Ä…daniom HTTP.



PrzeglÄ…danie wynikÃ³w ğŸ“Š: Dane wyÅ›wietlane w czytelnej formie tabelarycznej, zawierajÄ…cej szczegÃ³Å‚y kaÅ¼dej zeskanowanej witryny.



TrwaÅ‚e przechowywanie danych ğŸ’¾: Wyniki zapisywane w bazie MongoDB, co umoÅ¼liwia ich pÃ³Åºniejsze wykorzystanie.

ğŸ§© Struktura projektu

Projekt zostaÅ‚ podzielony na trzy moduÅ‚y, z ktÃ³rych kaÅ¼dy peÅ‚ni unikalnÄ… rolÄ™:





webscraper-interface ğŸ–¥ï¸: Interfejs uÅ¼ytkownika oparty na frameworku Flask. UmoÅ¼liwia wprowadzanie adresÃ³w URL i przeglÄ…danie wynikÃ³w w przejrzystej formie.



webscraper-engine ğŸ”: Silnik skanowania oparty na FastAPI. Odpowiada za asynchroniczne pobieranie i analizÄ™ stron przy uÅ¼yciu bibliotek BeautifulSoup i aiohttp.



mongo ğŸ—„ï¸: ModuÅ‚ integracji z bazÄ… danych MongoDB, wykorzystujÄ…cy asynchroniczny sterownik motor do przechowywania i pobierania danych.

ğŸ“ˆ Zbierane dane

Aplikacja gromadzi nastÄ™pujÄ…ce informacje z kaÅ¼dej zeskanowanej strony:





TytuÅ‚ strony ğŸ“œ: Pobierany z tagu <title>.



Adresy e-mail âœ‰ï¸: WyodrÄ™bniane za pomocÄ… wyraÅ¼eÅ„ regularnych.



Liczba linkÃ³w wewnÄ™trznych ğŸ”—: Zliczane na podstawie odnoÅ›nikÃ³w w obrÄ™bie tej samej domeny.



Struktura organizacyjna ğŸ“‘: OkreÅ›lana na podstawie nagÅ‚Ã³wkÃ³w (<h1>, <h2>, <h3>).



Liczba tagÃ³w HTML ğŸ·ï¸: Statystyki wystÄ…pieÅ„ poszczegÃ³lnych tagÃ³w w kodzie strony.

ğŸ› ï¸ UÅ¼yte technologie

Projekt opiera siÄ™ na nowoczesnym stosie technologicznym:





Python ğŸ: JÄ™zyk programowania zapewniajÄ…cy czytelnoÅ›Ä‡ i elastycznoÅ›Ä‡.



Flask ğŸŒ: Lekki framework webowy do tworzenia interfejsu uÅ¼ytkownika.



FastAPI ğŸš€: Asynchroniczny framework do budowy wydajnego API.



BeautifulSoup ğŸ§¹: Biblioteka do parsowania kodu HTML.



aiohttp ğŸŒ: Asynchroniczne Å¼Ä…dania HTTP dla szybkiego pobierania stron.



MongoDB ğŸ—ƒï¸: NoSQL-owa baza danych do przechowywania wynikÃ³w.



motor ğŸ”Œ: Asynchroniczny sterownik dla MongoDB.



Docker ğŸ³: Konteneryzacja zapewniajÄ…ca spÃ³jne Å›rodowisko uruchomieniowe.

ğŸ—ï¸ Architektura

Aplikacja dziaÅ‚a w oparciu o architekturÄ™ klient-serwer:





Interfejs (Flask) komunikuje siÄ™ z silnikiem (FastAPI) poprzez RESTful API.



Silnik przetwarza Å¼Ä…dania, skanuje strony i zapisuje wyniki do bazy MongoDB.



Docker zapewnia izolacjÄ™ i Å‚atwe uruchamianie wszystkich komponentÃ³w w sieci scraper-network.

ğŸš€ Jak uruchomiÄ‡?





Sklonuj repozytorium:

git clone https://github.com/<twoje-nazwa-uzytkownika>/webscraper.git
cd webscraper



Uruchom za pomocÄ… Docker Compose:

docker-compose up --build



OtwÃ³rz przeglÄ…darkÄ™ i przejdÅº na adres:

http://localhost:5000



WprowadÅº adresy URL, kliknij "Skanuj" i przeglÄ…daj wyniki! ğŸ‰

ğŸ“‚ Struktura katalogÃ³w

webscraper/
â”œâ”€â”€ interface/          # Kod moduÅ‚u interfejsu (Flask)
â”œâ”€â”€ engine/            # Kod moduÅ‚u silnika (FastAPI)
â”œâ”€â”€ docker-compose.yml  # Konfiguracja Dockera
â””â”€â”€ README.md          # Ten plik

ğŸ¤ Jak mogÄ™ pomÃ³c?

Chcesz dodaÄ‡ nowÄ… funkcjÄ™ lub zgÅ‚osiÄ‡ bÅ‚Ä…d? ğŸ’¡ OtwÃ³rz issue lub wyÅ›lij pull request! Wszelkie uwagi i sugestie sÄ… mile widziane. ğŸ˜Š

ğŸ“œ Licencja

Projekt jest dostÄ™pny na licencji MIT. SzczegÃ³Å‚y znajdziesz w pliku LICENSE.



Webscraper to idealne narzÄ™dzie dla kaÅ¼dego, kto chce szybko i efektywnie analizowaÄ‡ strony internetowe. DoÅ‚Ä…cz do nas i odkryj moc web scrapingu! ğŸŒŸ